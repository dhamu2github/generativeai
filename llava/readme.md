# Visual Question Answering with LLaVA

This is a web application built using Streamlit that enables users to ask questions about images. The app utilizes the LLaVA (Large Language and Vision Assistant) model to generate answers based on the uploaded image and user-provided question.

## Features
- Upload an image in `.jpg`, `.jpeg`, or `.png` format.
- Ask questions about the uploaded image.
- Get responses generated by the pre-trained LLaVA model (version 1.5).

## How It Works
1. The user uploads an image through the app interface.
2. The user enters a question about the uploaded image.
3. The app sends the image and question to the LLaVA model.
4. The model generates a response, which is displayed in the app.

## Requirements
- Python 3.8+
- Streamlit
- Transformers library (Hugging Face)
- PIL (Python Imaging Library)

## Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/dhamu2github/generativeai.git
   cd llava
   ```

2. Create a virtual environment (optional but recommended):
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
# Usage
1. Run the Streamlit app:
 ```bash
 streamlit run image_question_answer_app.py
 ```
2. Upload an image and enter a question about it in the app interface.

3. Click "Submit" to receive an answer from the model.

# Code Overview
image_question_answer_app.py
This is the main application file. It provides the interface using Streamlit for:

- Uploading an image
- Entering a question
- Displaying the generated response

image_question_answer_model.py
This file contains the logic to:

- Load the pre-trained LLaVA model (LlavaForConditionalGeneration) and its processor.
- Generate a response from the model based on the uploaded image and question.

# Example:
1. Upload an image of a busy city street.
2. Ask: "What is happening in the image?"
3. The app will display a response such as:
The image depicts a busy city street with people walking along the sidewalk and vehicles passing by.

# Notes:
- The LLaVA model is pre-trained and may have limitations in understanding certain images or questions.
- Ensure the uploaded image is clear and relevant to the question for better results.

# Acknowledgments
- Hugging Face Transformers for providing the LLaVA model.
- Streamlit for the interactive app framework.
1. [Hugging Face Transformers](https://huggingface.co/llava-hf/llava-1.5-7b-hf)
2. [Streamlit Documentation](https://docs.streamlit.io/)






